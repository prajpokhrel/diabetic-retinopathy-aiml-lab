{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c40bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7355c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c9d507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "dataset_type = ['training_set', 'testing_set']\n",
    "image_type = ['image', 'labels']\n",
    "ignore_dir = ['.DS_Store']\n",
    "lesions_type = ['microaneurysms', 'haemorrhages', 'hard_exudates', 'soft_exudates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a7c3d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_dataset = os.path.join(curr_dir, 'dataset/labels')\n",
    "images_dataset = os.path.join(curr_dir, 'dataset/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325df0d7-5142-48e9-9dce-7ac784f20723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a80eed3f",
   "metadata": {},
   "source": [
    "# Changing image labels to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d9ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_masks(infile, input_dir, output_dir = \"\", size = (4288, 2848)):\n",
    "    outfile = os.path.splitext(infile)[0]\n",
    "    extension = os.path.splitext(infile)[1]\n",
    "    \n",
    "    if (extension == \".jpg\"):\n",
    "        return\n",
    "    \n",
    "    if infile != outfile:\n",
    "        try:\n",
    "            # im = Image.open(os.path.join(label_dir, infile)) # slight modifications\n",
    "            im = Image.open(os.path.join(input_dir, infile))\n",
    "            gray = im.convert('L')\n",
    "            bw = gray.point(lambda x: 0 if x < 50 else 255, '1')\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            bw.save(os.path.join(output_dir, outfile[:-3] + \".jpg\"), \"JPEG\", quality = 100) # change this    \n",
    "        except IOError:\n",
    "            print(\"Cannot reduce image for\", infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a541492",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in dataset_type:\n",
    "    for lesions_folder in lesions_type:\n",
    "        image_dir = os.path.join(labels_dataset, f'{dataset}/{lesions_folder}')\n",
    "        output_dir = os.path.join(labels_dataset, f'{dataset}/{lesions_folder}_binary')\n",
    "        for image in os.listdir(image_dir):\n",
    "            create_binary_masks(image, image_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a3fb5",
   "metadata": {},
   "source": [
    "# Creating Images and Labels Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891afafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_and_label_patch(file, image_dir, mask_dir, out_image_dir, out_label_dir):\n",
    "#     for file in os.listdir(dir_mask):\n",
    "    outfile = os.path.splitext(file)[0]\n",
    "    extension = os.path.splitext(file)[1]\n",
    "\n",
    "    im = Image.open(os.path.join(mask_dir, file))\n",
    "    imd = Image.open(os.path.join(image_dir, file))\n",
    "    \n",
    "    if not os.path.exists(out_image_dir):\n",
    "        os.makedirs(out_image_dir)\n",
    "    if not os.path.exists(out_label_dir):\n",
    "        os.makedirs(out_label_dir)\n",
    "\n",
    "    patch_id = 0\n",
    "    for i in range(10):\n",
    "        for j in range(16):\n",
    "            top_y = i*256\n",
    "            if (i == 9):\n",
    "                top_y = 2336\n",
    "            top_x = j*256\n",
    "            if(j == 15):\n",
    "                top_x = 3776\n",
    "\n",
    "            im_crop = im.crop((top_x, top_y, top_x + 512, top_y+512))\n",
    "            imd_crop = imd.crop((top_x, top_y, top_x+512, top_y+512))\n",
    "\n",
    "            im_crop.save(os.path.join(out_label_dir, outfile+\"_p\"+str(patch_id)+extension), \"JPEG\", quality = 100)\n",
    "            imd_crop.save(os.path.join(out_image_dir, outfile+\"_p\"+str(patch_id)+extension), \"JPEG\", quality = 100)\n",
    "\n",
    "            patch_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f1dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in dataset_type:\n",
    "    images_dir = os.path.join(images_dataset, f'{dataset}')\n",
    "#     images_list = os.listdir(os.path.join(images_dataset, f'{dataset}'))\n",
    "    for lesions_folder in lesions_type:\n",
    "        label_images_dir = os.path.join(labels_dataset, f'{dataset}/{lesions_folder}_binary')\n",
    "        \n",
    "        # label_images_list = os.listdir(os.path.join(labels_dataset, f'{dataset}/{lesions_folder}_binary'))\n",
    "        for image in os.listdir(label_images_dir):\n",
    "            out_image_dir = os.path.join(images_dataset, f'{dataset}/{lesions_folder}_patch')\n",
    "            out_label_dir = os.path.join(labels_dataset, f'{dataset}/{lesions_folder}_binary_patch')\n",
    "            create_image_and_label_patch(image, images_dir, label_images_dir, out_image_dir, out_label_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972ab9bc",
   "metadata": {},
   "source": [
    "# Deleting Negative Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c3e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_negative_patches(image, images_patches_dir, label_images_patches_dir):\n",
    "    mask_image = cv2.imread(os.path.join(label_images_patches_dir, image))\n",
    "    if (mask_image.max() < 100):\n",
    "        os.remove(os.path.join(label_images_patches_dir, image))\n",
    "        os.remove(os.path.join(images_patches_dir, image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe312016",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in dataset_type:\n",
    "    images_dir = os.path.join(images_dataset, f'{dataset}')\n",
    "    for lesions_folder in lesions_type:\n",
    "        label_images_patches_dir = os.path.join(labels_dataset, f'{dataset}/{lesions_folder}_binary_patch')\n",
    "        for image in os.listdir(label_images_patches_dir):\n",
    "            images_patches_dir = os.path.join(images_dataset, f'{dataset}/{lesions_folder}_patch')\n",
    "            delete_negative_patches(image, images_patches_dir, label_images_patches_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100ebd8f",
   "metadata": {},
   "source": [
    "# Creating Patches, Performing Operations and then Merging it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f111a5",
   "metadata": {},
   "source": [
    "# (4288, 2848)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23053623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21227d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import models\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import losses\n",
    "# from tensorflow.python.keras import models\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.python.keras import backend as K\n",
    "import os\n",
    "from scipy.special import expit\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    # Flatten\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def model():\n",
    "    curr_dir = os.getcwd()\n",
    "    # model_path = os.path.join(curr_dir, 'model/hard_exudates_segmentation_model.keras')\n",
    "    # model_path = './model/hard_exudates_segmentation_model.keras'\n",
    "    model = load_model('model/hard_exudates_segmentation_model.keras', custom_objects={'bce_dice_loss': bce_dice_loss,\n",
    "                                                          'dice_loss': dice_loss})\n",
    "\n",
    "    return model\n",
    "\n",
    "def save_predicted_image(predicted_image, patch_id):\n",
    "    predicted_image = np.squeeze(predicted_image, axis=0)\n",
    "    predicted_image = np.squeeze(predicted_image)\n",
    "    threshold = 0.9\n",
    "    predicted_image = predicted_image > threshold\n",
    "    predicted_mask = (predicted_image.astype('uint8'))*255\n",
    "    output_image = Image.fromarray(predicted_mask)\n",
    "    output_image.save(f'image{patch_id}.jpg', \"JPEG\", quality=100)\n",
    "    return predicted_mask\n",
    "\n",
    "def predict_hx(image, patch_id, image_WH = (256, 256)):\n",
    "    myModel = model()\n",
    "    # image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, (256, 256))/255.\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    predicted_image = myModel.predict(image, steps=1)\n",
    "    predicted_image = tf.image.resize(predicted_image, (512, 512))\n",
    "    final_image = save_predicted_image(predicted_image, patch_id)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f637c049-fddf-4089-9744-d8626bdeb9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "sample_image = os.path.join(curr_dir, 'dataset/images/training_set')\n",
    "filename = 'IDRiD_10.jpg'\n",
    "outfile = os.path.splitext(filename)[0]\n",
    "extension = os.path.splitext(filename)[1]\n",
    "image = Image.open(os.path.join(sample_image, filename))\n",
    "# image = np.asarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce95de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image = np.zeros((2848, 4288), dtype=float)\n",
    "patch_id = 0\n",
    "for i in range(10): #10 6  \n",
    "  for j in range(16): #16 9\n",
    "    top_y = i * 256 #256 512\n",
    "    if (i==9): #9 5\n",
    "      top_y = 2336\n",
    "    top_x = j * 256 #256 512\n",
    "    if (j==15): #15 8\n",
    "      top_x = 3776\n",
    "    # image_crop = image[top_y:top_y+512, top_x:top_x+512]\n",
    "    image_crop = image.crop((top_x, top_y, top_x + 512, top_y+512))\n",
    "    predicted_crop = predict_hx(image_crop, patch_id)\n",
    "    predicted_image[top_y:top_y+512, top_x:top_x+512] = np.maximum(predicted_image[top_y:top_y+512, top_x:top_x+512], predicted_crop)\n",
    "    patch_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1185c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_save = Image.fromarray(predicted_image)\n",
    "image = predicted_save.convert('RGB')\n",
    "image.save('predicted_image.jpg', \"JPEG\", quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a83aab-3e7e-4755-9221-0ce2b7bfbd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca357e7-b1cf-485e-8ed5-c5337a97cfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
